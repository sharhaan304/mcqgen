{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_24692\\1077716165.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm=ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo\", temperature=0.3)\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables = ['text','number','subject', 'tone', 'response_json'],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_24692\\3314014951.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key='quiz', verbose=True)\n"
     ]
    }
   ],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key='quiz', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(input_variables = ['subject', 'quiz'], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key='review', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(chains=[quiz_chain, review_chain], input_variables=['text','number','subject', 'tone', 'response_json'],output_variables=['quiz','review'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Asus\\mcqgen\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company was founded in 2016 by French entrepreneurs ClÃ©ment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.[2] The company was named after the U+1F917 ðŸ¤— HUGGING FACE emoji.[2] After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.\n",
      "\n",
      "In March 2021, Hugging Face raised US$40 million in a Series B funding round.[3]\n",
      "\n",
      "On April 28, 2021, the company launched the BigScience Research Workshop in collaboration with several other research groups to release an open large language model.[4] In 2022, the workshop concluded with the announcement of BLOOM, a multilingual large language model with 176 billion parameters.[5][6]\n",
      "\n",
      "In December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.[7]\n",
      "\n",
      "On May 5, 2022, the company announced its Series C funding round led by Coatue and Sequoia.[8] The company received a $2 billion valuation.\n",
      "\n",
      "On August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports SaaS or on-premises deployment.[9]\n",
      "\n",
      "In February 2023, the company announced partnership with Amazon Web Services (AWS) which would allow Hugging Face's products available to AWS customers to use them as the building blocks for their custom applications. The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by AWS.[10][11][12]\n",
      "\n",
      "In August 2023, the company announced that it raised $235 million in a Series D funding, at a $4.5 billion valuation. The funding was led by Salesforce, and notable participation came from Google, Amazon, Nvidia, AMD, Intel, IBM, and Qualcomm.[13]\n",
      "\n",
      "In June 2024, the company announced, along with Meta and Scaleway, their launch of a new AI accelerator program for European startups. This initiative aims to help startups integrate open foundation models into their products, accelerating the EU AI ecosystem. The program, based at STATION F in Paris, will run from September 2024 to February 2025. Selected startups will receive mentoring, access to AI models and tools, and Scalewayâ€™s computing power.[14]\n",
      "\n",
      "On September 23, 2024, to further the International Decade of Indigenous Languages, Hugging Face teamed up with Meta and UNESCO to launch a new online language translator [15] built on Meta's No Language Left Behind open-source AI model, enabling free text translation across 200 languages, including many low-resource languages.[16]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the python dictionary into JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 3\n",
    "SUBJECT = \"Hugging Face\"\n",
    "TONE = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_24692\\2654919708.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response=generate_evaluate_chain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:The company was founded in 2016 by French entrepreneurs ClÃ©ment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.[2] The company was named after the U+1F917 ðŸ¤— HUGGING FACE emoji.[2] After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.\n",
      "\n",
      "In March 2021, Hugging Face raised US$40 million in a Series B funding round.[3]\n",
      "\n",
      "On April 28, 2021, the company launched the BigScience Research Workshop in collaboration with several other research groups to release an open large language model.[4] In 2022, the workshop concluded with the announcement of BLOOM, a multilingual large language model with 176 billion parameters.[5][6]\n",
      "\n",
      "In December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.[7]\n",
      "\n",
      "On May 5, 2022, the company announced its Series C funding round led by Coatue and Sequoia.[8] The company received a $2 billion valuation.\n",
      "\n",
      "On August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports SaaS or on-premises deployment.[9]\n",
      "\n",
      "In February 2023, the company announced partnership with Amazon Web Services (AWS) which would allow Hugging Face's products available to AWS customers to use them as the building blocks for their custom applications. The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by AWS.[10][11][12]\n",
      "\n",
      "In August 2023, the company announced that it raised $235 million in a Series D funding, at a $4.5 billion valuation. The funding was led by Salesforce, and notable participation came from Google, Amazon, Nvidia, AMD, Intel, IBM, and Qualcomm.[13]\n",
      "\n",
      "In June 2024, the company announced, along with Meta and Scaleway, their launch of a new AI accelerator program for European startups. This initiative aims to help startups integrate open foundation models into their products, accelerating the EU AI ecosystem. The program, based at STATION F in Paris, will run from September 2024 to February 2025. Selected startups will receive mentoring, access to AI models and tools, and Scalewayâ€™s computing power.[14]\n",
      "\n",
      "On September 23, 2024, to further the International Decade of Indigenous Languages, Hugging Face teamed up with Meta and UNESCO to launch a new online language translator [15] built on Meta's No Language Left Behind open-source AI model, enabling free text translation across 200 languages, including many low-resource languages.[16]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 3 multiple choice questions for Hugging Face students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 3 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for Hugging Face students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"When was Hugging Face founded?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"2014\",\n",
      "            \"b\": \"2016\",\n",
      "            \"c\": \"2018\",\n",
      "            \"d\": \"2020\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"What was the original focus of Hugging Face before pivoting to machine learning?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Social media platform\",\n",
      "            \"b\": \"E-commerce website\",\n",
      "            \"c\": \"Chatbot app for teenagers\",\n",
      "            \"d\": \"Fitness tracking app\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Which company led the Series D funding round for Hugging Face in August 2023?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Salesforce\",\n",
      "            \"b\": \"Google\",\n",
      "            \"c\": \"Amazon\",\n",
      "            \"d\": \"Nvidia\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:1506\n",
      "Prompt Tokens:1168\n",
      "Completion Tokens:338\n",
      "Total Cost:0.0024280000000000005\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The company was founded in 2016 by French entrepreneurs ClÃ©ment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.[2] The company was named after the U+1F917 ðŸ¤— HUGGING FACE emoji.[2] After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.\\n\\nIn March 2021, Hugging Face raised US$40 million in a Series B funding round.[3]\\n\\nOn April 28, 2021, the company launched the BigScience Research Workshop in collaboration with several other research groups to release an open large language model.[4] In 2022, the workshop concluded with the announcement of BLOOM, a multilingual large language model with 176 billion parameters.[5][6]\\n\\nIn December 2022, the company acquired Gradio, an open source library built for developing machine learning applications in Python.[7]\\n\\nOn May 5, 2022, the company announced its Series C funding round led by Coatue and Sequoia.[8] The company received a $2 billion valuation.\\n\\nOn August 3, 2022, the company announced the Private Hub, an enterprise version of its public Hugging Face Hub that supports SaaS or on-premises deployment.[9]\\n\\nIn February 2023, the company announced partnership with Amazon Web Services (AWS) which would allow Hugging Face's products available to AWS customers to use them as the building blocks for their custom applications. The company also said the next generation of BLOOM will be run on Trainium, a proprietary machine learning chip created by AWS.[10][11][12]\\n\\nIn August 2023, the company announced that it raised $235 million in a Series D funding, at a $4.5 billion valuation. The funding was led by Salesforce, and notable participation came from Google, Amazon, Nvidia, AMD, Intel, IBM, and Qualcomm.[13]\\n\\nIn June 2024, the company announced, along with Meta and Scaleway, their launch of a new AI accelerator program for European startups. This initiative aims to help startups integrate open foundation models into their products, accelerating the EU AI ecosystem. The program, based at STATION F in Paris, will run from September 2024 to February 2025. Selected startups will receive mentoring, access to AI models and tools, and Scalewayâ€™s computing power.[14]\\n\\nOn September 23, 2024, to further the International Decade of Indigenous Languages, Hugging Face teamed up with Meta and UNESCO to launch a new online language translator [15] built on Meta's No Language Left Behind open-source AI model, enabling free text translation across 200 languages, including many low-resource languages.[16]\",\n",
       " 'number': 3,\n",
       " 'subject': 'Hugging Face',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '\\n{\\n    \"1\": {\\n        \"mcq\": \"When was Hugging Face founded?\",\\n        \"options\": {\\n            \"a\": \"2014\",\\n            \"b\": \"2016\",\\n            \"c\": \"2018\",\\n            \"d\": \"2020\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"What was the original focus of Hugging Face before pivoting to machine learning?\",\\n        \"options\": {\\n            \"a\": \"Social media platform\",\\n            \"b\": \"E-commerce website\",\\n            \"c\": \"Chatbot app for teenagers\",\\n            \"d\": \"Fitness tracking app\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"Which company led the Series D funding round for Hugging Face in August 2023?\",\\n        \"options\": {\\n            \"a\": \"Salesforce\",\\n            \"b\": \"Google\",\\n            \"c\": \"Amazon\",\\n            \"d\": \"Nvidia\"\\n        },\\n        \"correct\": \"a\"\\n    }\\n}',\n",
       " 'review': 'Complexity Analysis: The quiz questions are straightforward and factual, testing knowledge of Hugging Face\\'s history and funding. The language used is clear and concise, suitable for students familiar with the company. The questions do not require deep analysis or critical thinking.\\n\\nSuggested Changes: To better fit student abilities, consider adding more context to the questions or providing hints for those less familiar with Hugging Face. For example, \"Before pivoting to machine learning, Hugging Face was known for developing a popular ________ app for teenagers.\" This approach can enhance engagement and understanding.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get('quiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'When was Hugging Face founded?',\n",
       "  'Choices': 'a: 2014 | b: 2016 | c: 2018 | d: 2020',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What was the original focus of Hugging Face before pivoting to machine learning?',\n",
       "  'Choices': 'a: Social media platform | b: E-commerce website | c: Chatbot app for teenagers | d: Fitness tracking app',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'Which company led the Series D funding round for Hugging Face in August 2023?',\n",
       "  'Choices': 'a: Salesforce | b: Google | c: Amazon | d: Nvidia',\n",
       "  'Correct': 'a'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"HuggingFace.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
